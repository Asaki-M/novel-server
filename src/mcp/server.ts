#!/usr/bin/env node

import { InferenceClient } from '@huggingface/inference'
import { Server } from '@modelcontextprotocol/sdk/server/index.js'
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js'
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
} from '@modelcontextprotocol/sdk/types.js'
import { z } from 'zod'
import imageStorageService from '../services/imageStorageService.js'
import langchainService from '../services/langchainService.js'

/**
 * æ ‡å‡† MCP æœåŠ¡å™¨
 *
 * æä¾›ä¸¤ä¸ªæ ¸å¿ƒå·¥å…·ï¼š
 * 1. intent_recognition - æ„å›¾è¯†åˆ«
 * 2. generate_illustration - æ–‡ç”Ÿå›¾
 */

// åˆ›å»º MCP æœåŠ¡å™¨å®ä¾‹
const server = new Server(
  {
    name: 'novel-mcp-server',
    version: '1.0.0',
  },
  {
    capabilities: {
      tools: {},
    },
  },
)

// ==================== å·¥å…·å®ç° ====================

/**
 * æ„å›¾è¯†åˆ«å·¥å…·
 * åˆ†æç”¨æˆ·æ¶ˆæ¯ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆå›¾ç‰‡
 */
async function recognizeIntent(
  message: string,
  context?: Array<{ role: 'user' | 'assistant' | 'system', content: string }>,
): Promise<{
  intent: 'text_to_image' | 'normal_chat'
  confidence: number
  reasoning: string
}> {
  try {
    // æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    const contextStr = context
      ? context.slice(-6).map(m => `${m.role}: ${m.content}`).join('\n')
      : ''

    // æ„å»ºåˆ†ææç¤ºè¯
    const prompt = `åˆ†æç”¨æˆ·æ¶ˆæ¯æ„å›¾ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆå›¾ç‰‡ã€‚

${contextStr ? `ä¸Šä¸‹æ–‡ï¼š\n${contextStr}\n\n` : ''}ç”¨æˆ·æ¶ˆæ¯ï¼š${message}

åˆ¤æ–­è§„åˆ™ï¼š
1. æ˜ç¡®è¦æ±‚ç”Ÿæˆã€ç”»ã€åˆ›ä½œå›¾ç‰‡/æ’ç”»ç­‰ â†’ text_to_image
2. æè¿°å…·ä½“çš„äººç‰©ã€åœºæ™¯ã€ç‰©å“å¤–è§‚ç­‰ â†’ text_to_image  
3. æ™®é€šèŠå¤©ã€è¯¢é—®é—®é¢˜ç­‰ â†’ normal_chat

è¿”å›JSONæ ¼å¼ï¼š
{
  "intent": "text_to_image" | "normal_chat",
  "confidence": 0.0-1.0,
  "reasoning": "åˆ¤æ–­ç†ç”±"
}`

    // è°ƒç”¨ LangChain æœåŠ¡è¿›è¡Œåˆ†æ
    const result = await langchainService.invoke(
      [{ role: 'user', content: prompt }],
      {
        temperature: 0.1,
        max_tokens: 150,
      },
    )

    // è§£æç»“æœ
    let parsed
    try {
      parsed = JSON.parse(result.content)
    }
    catch {
      // è§£æå¤±è´¥æ—¶çš„å›é€€ç­–ç•¥
      const imageKeywords = ['ç”Ÿæˆ', 'ç”»', 'åˆ›ä½œ', 'åˆ¶ä½œ', 'å›¾ç‰‡', 'æ’ç”»', 'å›¾åƒ']
      const needsImage = imageKeywords.some(keyword => message.includes(keyword))
      parsed = {
        intent: needsImage ? 'text_to_image' : 'normal_chat',
        confidence: 0.6,
        reasoning: 'è§£æå¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…',
      }
    }

    return {
      intent: parsed.intent === 'text_to_image' ? 'text_to_image' : 'normal_chat',
      confidence: Math.max(0, Math.min(1, parsed.confidence || 0.5)),
      reasoning: parsed.reasoning || 'æ— æ¨ç†è¿‡ç¨‹',
    }
  }
  catch (error) {
    console.error('æ„å›¾è¯†åˆ«å¤±è´¥:', error)
    return {
      intent: 'normal_chat',
      confidence: 0.5,
      reasoning: `æœåŠ¡å¼‚å¸¸: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`,
    }
  }
}

/**
 * æ–‡ç”Ÿå›¾å·¥å…·
 * æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆæ’ç”»å›¾ç‰‡
 */
async function generateIllustration(input: {
  prompt: string
  sessionId: string
  style?: string
  size?: '512x512' | '768x768' | '1024x1024'
  quality?: 'standard' | 'high'
}): Promise<{
  url?: string
  publicUrl?: string
  path?: string
  base64?: string
  prompt: string
  timestamp: number
  error?: boolean
  message?: string
}> {
  try {
    // æ£€æŸ¥ HuggingFace Token
    const token = process.env['HF_TOKEN']
    if (!token) {
      throw new Error('HF_TOKEN ç¯å¢ƒå˜é‡æœªé…ç½®')
    }

    // åˆ›å»ºæ¨ç†å®¢æˆ·ç«¯
    const client = new InferenceClient(token)

    // å¢å¼ºæç¤ºè¯
    let enhancedPrompt = input.prompt
    enhancedPrompt = `${enhancedPrompt}, ${input.style || 'anime'} style`
    if (input.quality === 'high') {
      enhancedPrompt = `${enhancedPrompt}, high quality, detailed, masterpiece`
    }

    console.log(`ğŸ¨ å¼€å§‹ç”Ÿæˆå›¾ç‰‡: ${enhancedPrompt}`)

    // è°ƒç”¨æ–‡ç”Ÿå›¾ API
    let output: any
    try {
      // å°è¯•å¤šä¸ªæ¨¡å‹ï¼Œæé«˜æˆåŠŸç‡
      console.log(`ğŸ¯ å°è¯•ä½¿ç”¨æ¨¡å‹: Jonjew/NSFWHanfu`)
      output = await client.textToImage({
        model: 'Jonjew/NSFWHanfu',
        inputs: enhancedPrompt,
        parameters: {
          num_inference_steps: 20,
          guidance_scale: 7.5,
        },
      })
      console.log(`output: ${output}`)
      console.log(`ğŸ“¸ HuggingFace API è°ƒç”¨æˆåŠŸï¼Œè¾“å‡ºç±»å‹: ${typeof output}, æ„é€ å‡½æ•°: ${output?.constructor?.name}`)
    }
    catch (hfError) {
      console.error('ğŸš¨ HuggingFace API è°ƒç”¨å¤±è´¥:', hfError)
      throw new Error(`HuggingFace API é”™è¯¯: ${hfError instanceof Error ? hfError.message : 'æœªçŸ¥é”™è¯¯'}`)
    }

    // å¤„ç†å›¾ç‰‡æ•°æ®å¹¶è½¬æ¢ä¸ºçº¯ base64
    let base64Data: string

    console.log(`ğŸ” å¼€å§‹å¤„ç†å›¾ç‰‡æ•°æ®...`)
    console.log(`ğŸ“Š è¾“å‡ºæ•°æ®ä¿¡æ¯: ç±»å‹=${typeof output}, é•¿åº¦=${output?.length || 'N/A'}, æ„é€ å‡½æ•°=${output?.constructor?.name}`)

    if (output instanceof ArrayBuffer) {
      console.log(`ğŸ“¦ å¤„ç† ArrayBuffer æ•°æ®ï¼Œå¤§å°: ${output.byteLength} å­—èŠ‚`)
      base64Data = Buffer.from(output).toString('base64')
    }
    else if (output instanceof Uint8Array) {
      console.log(`ğŸ“¦ å¤„ç† Uint8Array æ•°æ®ï¼Œå¤§å°: ${output.length} å­—èŠ‚`)
      base64Data = Buffer.from(output).toString('base64')
    }
    else if (output instanceof Buffer) {
      console.log(`ğŸ“¦ å¤„ç† Buffer æ•°æ®ï¼Œå¤§å°: ${output.length} å­—èŠ‚`)
      base64Data = output.toString('base64')
    }
    else {
      // å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œå°è¯•è§£æ
      const outputStr = String(output)
      console.log(`ğŸ“¦ å¤„ç†å­—ç¬¦ä¸²æ•°æ®ï¼Œé•¿åº¦: ${outputStr.length}, å‰100å­—ç¬¦: ${outputStr.substring(0, 100)}`)

      if (outputStr.startsWith('data:image/')) {
        // å¦‚æœæ˜¯ data URL æ ¼å¼ï¼Œæå– base64 éƒ¨åˆ†
        const base64Match = outputStr.match(/^data:image\/[a-zA-Z]*;base64,(.+)$/)
        if (base64Match && base64Match[1]) {
          base64Data = base64Match[1]
          console.log(`âœ… ä» data URL æå– base64 æ•°æ®`)
        }
        else {
          throw new Error('æ— æ³•ä» data URL ä¸­æå– base64 æ•°æ®')
        }
      }
      else if (outputStr.length > 100 && /^[A-Z0-9+/=]+$/i.test(outputStr)) {
        // å‡è®¾æ˜¯çº¯ base64
        base64Data = outputStr
        console.log(`âœ… è¯†åˆ«ä¸ºçº¯ base64 æ•°æ®`)
      }
      else {
        console.error(`âŒ æ— æ³•è¯†åˆ«çš„æ•°æ®æ ¼å¼: ${outputStr.substring(0, 200)}`)
        throw new Error(`æ— æ³•è¯†åˆ«çš„å›¾ç‰‡æ•°æ®æ ¼å¼ï¼Œæ•°æ®ç±»å‹: ${typeof output}`)
      }
    }

    if (!base64Data || base64Data.length < 100) {
      throw new Error(`å›¾ç‰‡æ•°æ®å¼‚å¸¸ï¼Œbase64 é•¿åº¦: ${base64Data?.length || 0}`)
    }

    console.log(`ğŸ“¸ å›¾ç‰‡æ•°æ®å¤„ç†å®Œæˆï¼Œbase64 é•¿åº¦: ${base64Data.length}`)

    // å°è¯•ä¸Šä¼ åˆ°å­˜å‚¨æœåŠ¡
    try {
      const storageResult = await imageStorageService.uploadBase64Image(base64Data, input.sessionId)
      console.log(`âœ… å›¾ç‰‡ä¸Šä¼ æˆåŠŸ: ${storageResult.url}`)

      return {
        url: storageResult.url,
        publicUrl: storageResult.publicUrl,
        path: storageResult.path,
        prompt: input.prompt,
        timestamp: Date.now(),
      }
    }
    catch (uploadError) {
      console.warn('å›¾ç‰‡ä¸Šä¼ å¤±è´¥ï¼Œè¿”å›base64æ•°æ®:', uploadError)

      return {
        base64: base64Data,
        prompt: input.prompt,
        timestamp: Date.now(),
        error: false,
        message: 'å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼Œä½†ä¸Šä¼ å¤±è´¥ï¼Œè¿”å›base64æ•°æ®',
      }
    }
  }
  catch (error) {
    console.error('å›¾ç‰‡ç”Ÿæˆå¤±è´¥:', error)
    return {
      error: true,
      message: error instanceof Error ? error.message : 'å›¾ç‰‡ç”Ÿæˆå¤±è´¥',
      prompt: input.prompt,
      timestamp: Date.now(),
    }
  }
}

// ==================== MCP åè®®å¤„ç† ====================

// å®šä¹‰å·¥å…·å‚æ•° schema
const intentRecognitionSchema = z.object({
  message: z.string(),
  context: z.array(z.object({
    role: z.enum(['user', 'assistant', 'system']),
    content: z.string(),
  })).optional(),
})

const generateIllustrationSchema = z.object({
  prompt: z.string(),
  sessionId: z.string(),
  style: z.string().default('anime'),
  size: z.enum(['512x512', '768x768', '1024x1024']).default('512x512'),
  quality: z.enum(['standard', 'high']).default('high'),
})

// å·¥å…·è°ƒç”¨å¤„ç†
server.setRequestHandler(CallToolRequestSchema, async (request) => {
  const { name, arguments: args } = request.params

  try {
    if (name === 'intent_recognition') {
      const validatedArgs = intentRecognitionSchema.parse(args)
      const result = await recognizeIntent(validatedArgs.message, validatedArgs.context)
      return {
        content: [{ type: 'text', text: JSON.stringify(result, null, 2) }],
      }
    }

    if (name === 'generate_illustration') {
      const validatedArgs = generateIllustrationSchema.parse(args)
      const result = await generateIllustration(validatedArgs)
      return {
        content: [{ type: 'text', text: JSON.stringify(result, null, 2) }],
      }
    }

    throw new Error(`æœªçŸ¥å·¥å…·: ${name}`)
  }
  catch (error) {
    console.error(`å·¥å…·è°ƒç”¨å¤±è´¥ [${name}]:`, error)
    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          error: true,
          message: error instanceof Error ? error.message : 'å·¥å…·è°ƒç”¨å¤±è´¥',
        }, null, 2),
      }],
    }
  }
})

// å·¥å…·åˆ—è¡¨
server.setRequestHandler(ListToolsRequestSchema, async () => {
  return {
    tools: [
      {
        name: 'intent_recognition',
        description: 'è¯†åˆ«ç”¨æˆ·æ¶ˆæ¯çš„æ„å›¾ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆå›¾ç‰‡',
        inputSchema: {
          type: 'object',
          properties: {
            message: { type: 'string', description: 'ç”¨æˆ·æ¶ˆæ¯å†…å®¹' },
            context: {
              type: 'array',
              description: 'å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰',
              items: {
                type: 'object',
                properties: {
                  role: { type: 'string', enum: ['user', 'assistant', 'system'] },
                  content: { type: 'string' },
                },
              },
            },
          },
          required: ['message'],
        },
      },
      {
        name: 'generate_illustration',
        description: 'æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆæ’ç”»å›¾ç‰‡',
        inputSchema: {
          type: 'object',
          properties: {
            prompt: { type: 'string', description: 'å›¾ç‰‡ç”Ÿæˆæç¤ºè¯' },
            sessionId: { type: 'string', description: 'ä¼šè¯ID' },
            style: { type: 'string', description: 'å›¾ç‰‡é£æ ¼', default: 'anime' },
            size: {
              type: 'string',
              enum: ['512x512', '768x768', '1024x1024'],
              description: 'å›¾ç‰‡å°ºå¯¸',
              default: '512x512',
            },
            quality: {
              type: 'string',
              enum: ['standard', 'high'],
              description: 'å›¾ç‰‡è´¨é‡',
              default: 'high',
            },
          },
          required: ['prompt', 'sessionId'],
        },
      },
    ],
  }
})

// å¯åŠ¨æœåŠ¡å™¨
async function main() {
  const transport = new StdioServerTransport()
  await server.connect(transport)
  console.error('ğŸš€ MCP æœåŠ¡å™¨å·²å¯åŠ¨')
}

// é”™è¯¯å¤„ç†
process.on('uncaughtException', (error) => {
  console.error('æœªæ•è·çš„å¼‚å¸¸:', error)
  process.exit(1)
})

process.on('unhandledRejection', (reason, _promise) => {
  console.error('æœªå¤„ç†çš„ Promise æ‹’ç»:', reason)
  process.exit(1)
})

// å¯åŠ¨æœåŠ¡å™¨
main().catch((error) => {
  console.error('MCP æœåŠ¡å™¨å¯åŠ¨å¤±è´¥:', error)
  process.exit(1)
})
